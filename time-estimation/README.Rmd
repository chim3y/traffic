---
title: "Estimation of time-spent on AUSA toll booths"
author: "Julián Ailán"
params:
  date: "!r Sys.Date()"
output:
  github_document:
    toc: yes
    pandoc_args: --webtex
---

```{r setupandrequiredpackages, include=FALSE, fig.align="center"}
knitr::opts_chunk$set(echo = TRUE)

rm(list = ls()); gc();

packages_to_include <- c(
  "dplyr", "tibble", "ggplot2", "ff", "reshape2", "tseries"
)

lapply (
  packages_to_include, # From this list ...
  require, # ... include them as packages.
  character.only = T
)

rm(packages_to_include)
```

### Objective
This project consists on estimating time-spent by drivers on AUSA toll booths in Buenos Aires highways. Currently users of these highways experience excessive amount of time waiting to go through toll booths on peak hours. In addition to estimating this metric, an analysis of whether contextual variables like toll-booth fee or oil prices have an impact on the behavior and amount of users commuting through these highways.

### Joining the traffic dataset with the oil dataset
The `traffic.csv` dataset previously analized [here](https://github.com/tulians/traffic/tree/master/descriptive) has a file size of approximately 562MB, while the `oil_prices.csv` dataset is only 11.2KB. We'll be merging both files in an inner join fashion, using the year and month columns via the [`merge()`](https://www.rdocumentation.org/packages/base/versions/3.6.0/topics/merge) function. As a result of this merge each existing row in `traffic.csv` will be repeated 4 times, one per each oil type, thus taking the final, merged, dataset to an approximate size of 2.2GB.

R requires that variables are stored in RAM in its entirety, so managing a dataframe this big could be imposible for some machines if no alternate processing is performed. For this reason is that the [`ff`](https://cran.r-project.org/web/packages/ff/index.html) package will be used.

```{r readingunifiedfile, echo=FALSE}
datasets_dir <- "../datasets"
# Directory where `ff` stores temporary files. Take into account temporary files
# will fill up this directory through time. Make sure to delete them once in a
# while.
options(
  fftempdir = file.path(datasets_dir, "tmp")
)
unified_ff <- read.csv.ffdf (
  file = file.path(datasets_dir, "unified.csv")
)
rm(datasets_dir)
```

### Analysis of oil price behavior
The oil prices dataset consists of monthly prices of different types of oil: super, premium, gasoil, and euro. The four of them experienced a steady increase since 2008 until 2018, which is illustrated in Figure 1.

```{r pricethroughtime, echo=FALSE}
oil_price <- unified_ff %>% as_tibble() %>%
  group_by(
    year_,
    oil_type
  ) %>%
  summarise(
    price = max(price)
  )

ggplot(data = oil_price,
       aes(x = year_, y = price, group = oil_type)) +
  geom_line(aes(color = oil_type)) +
  geom_point(alpha = 1 / 5) +
  labs(x = NULL, y = "ARS ($)",
       title = "Price of oil through time", caption = "Figure 1") +
  theme_minimal()

rm(oil_price)

ff_df <- unified_ff %>% as_tibble() %>%
  select(year_, month_, amount, price) %>%
  filter(year_ >= 2014) %>%
  group_by(year_, month_) %>%
  summarise(
    price = mean(price),
    vehicles = sum(amount)
  )

pv_correlation <- cor(ff_df$price, ff_df$vehicles)
```

Building on top of the previous analysis of traffic patterns performed [here](https://github.com/tulians/traffic/blob/master/descriptive/README.md), it would be intersting to analyze whether there was a correlation between the rate at which the number of vehicles passing through toll booths [started to grow month-over-month](https://github.com/tulians/traffic/blob/master/descriptive/README_files/figure-markdown_github/trend-1.png), and the month-over-month (M-o-M) increase in oil prices depicted in Figure 1. As seen in Figure 2 (condidering only information from January 2014 onwards, after the [unexpected growth](https://github.com/tulians/traffic/tree/master/descriptive#increment-in-traffic)) there is barely a linear relation between these two differences, which is represented by the Pearson correlation coefficient of `r pv_correlation`. This correlation, even though it's not strong, it's positive, which implies that an increase in oil prices does not necessarily result in a decrease in traffic volume, but rather the opposite in this case.

```{r correlationgraph, echo=FALSE}
ggplot(data = ff_df,
       aes(x = price, y = vehicles)) +
  geom_point(alpha = 2 / 5) +
  geom_smooth(method = "lm") +
  labs(x = "Oil price (ARS)",
       y = "Volume of vehicles",
       title = "Relation of oil price and amount of vehicles",
       caption = "Figure 2") +
  theme_minimal()

ff_df_differences <- data.frame (
  year_ = diff(ff_df$year_),
  month_ = diff(ff_df$month_),
  price = diff(ff_df$price / max(ff_df$price)),
  vehicles = diff(ff_df$vehicles / max(ff_df$vehicles))
)

ff_df_differences$vehicles[which.min(ff_df_differences$vehicles)] <-
  mean(ff_df_differences$vehicles)
ff_df_differences$vehicles[which.max(ff_df_differences$vehicles)] <-
  mean(ff_df_differences$vehicles)

# Move from wide to tall format to plot multiple series in the same graph.
ff_df_tall <- melt (
  ff_df_differences,
  id.vars = c("year_", "month_"),
  measure.vars = c("price", "vehicles"),
  variable.name = "series",
  value.name = "measurement") %>%
  select(series, measurement) %>%
  group_by(series) %>%
  mutate(id = row_number()
)

diff_correlation <- cor(ff_df_differences$price, ff_df_differences$vehicles)
```

A more interesting approach in the search for a relation between vehicle volume and oil price would be to look at the M-o-M differences of each time series. Figure 3 shows the behavior through time of the difference of each of the variables, which was computed over the normalized series. Again, computing the correlation between both differences yields a positive number, `r diff_correlation`, which shows non-conclusive evidence that an increase in oil price could impact the volume of vehicles passing through toll booths (at least not in a month by month basis).

```{r differencesgraph, echo=FALSE}
ggplot(data = ff_df_tall,
       aes(x = id, y = measurement, group = series, colour = series)) +
  geom_line() +
  labs(x = "index",
       y = "Delta (M_i - M_{i-1})",
       title = "M-o-M differences for both amount of vehicles and oil prices",
       caption = "Figure 3") +
  theme_minimal()

rm(ff_df_differences, ff_df_tall, pv_correlation, diff_correlation, ff_df)
```

### Time spent waiting on queues estimation
It's usual to see vehicles queuing in Buenos Aires' toll booth plazas at peak hours. More than 1.5M vehicles enter the city each day, most of which are people commuting to work. In this context toll booths regularly feature queues that extend through kilometers in highways. The objective of this section is to accurately estimate the average time a given driver waits in order go through the toll booth.

In order to achieve this goal we need to have concrete figures of both the rate at which cars arrive to the toll booths $\lambda$, and also the rate at which cars can be serviced $\mu$, meaning, the amount of cars that go through the toll booth at a given period of time. Both of the rates would be averages, as they will be considering times where there is a long queue, as well as times where there's no queue at all. The $\rho=\lambda/\mu$ ratio, known as traffic intensity, will help us identify the average behavior of the queue, given that if $\rho < 1$ there is a finite probability that the queue can be handled by the booth; on the other hand if $\rho \geq 1$ the queue length will become longer and longer without limit up to infinity (at least in theoretical terms).

Given that we have information of traffic flow along several toll booths, we'll use it to derive these two coefficients, and find the value of $\rho$ for each of the toll booth plazas. Depending on the dimension of this ratio, we'll need to compute waiting time one way or another. More details on this calculations will be given in future sections.

#### Important considerations
##### Toll booth plaza naming, geolocation, and amount of toll booths per plaza
Up to now we've been working with the dataset without validating whether all the information provided was accurate. However, there were mentions in the [previous section](https://github.com/tulians/traffic/tree/master/descriptive#increment-in-traffic) to strange patterns in data. In this section we'll validate that every toll booth plaza name provided in the dataset actually exists, and also where it's located geographically. To perform this validation we'll use a [map](https://www.ausa.com.ar/documentos/AUSA-Mapa-Autopistas.pdf) provided by the same company the information is about.

* `Alberdi`: _Juan Bautista Alberdi_ is an avenue located at [(-34.6429211, -58.4910398)](https://www.google.com/maps/@-34.6429211,-58.4910398,18z) which provides a way to enter the _Perito Moreno_ highway. However, there is no toll booth in such entrance. Looking at the previously mentioned [map](https://www.ausa.com.ar/documentos/AUSA-Mapa-Autopistas.pdf), we can validate there is no toll booth sign in the entrance. However, there is such a sign in an actual toll booth in the _25 de Mayo_ highway, located at [(-34.6252954,-58.4022763)](https://www.google.com/maps/@-34.6252954,-58.4022763,17z), under the name of _Peaje Alberti_ (mind that they differ in one character, as the latter has a _t_ instead of a _d_). Given this context, most likely the information we see for _Alberdi_ corresponds to _Alberti_, as the latter is the one that has a toll booth, while the former does not. Something important to mention about this toll booth is that it counts with [3 lanes](https://www.google.com/maps/@-34.6253084,-58.399961,3a,75y,296.16h,87.96t/data=!3m7!1e1!3m5!1szK1wuTFcAlvJddIHqUlZWw!2e0!6s%2F%2Fgeo0.ggpht.com%2Fcbk%3Fpanoid%3DzK1wuTFcAlvJddIHqUlZWw%26output%3Dthumbnail%26cb_client%3Dmaps_sv.tactile.gps%26thumb%3D2%26w%3D203%26h%3D100%26yaw%3D317.5315%26pitch%3D0%26thumbfov%3D100!7i13312!8i6656) to enter the city, and [2 lanes](https://www.google.com/maps/@-34.6257901,-58.4001986,3a,75y,84.02h,99.26t/data=!3m6!1e1!3m4!1sTeolsLKGK9ckp3WVWxFLQg!2e0!7i13312!8i6656) to leave. For the sake of the code, I'll keep on using the `Alberdi` label, but everything will be computed with _Peaje Alberti_ in mind.

* `Avellaneda`: the _Parque Avellaneda_ toll booth is located at [(-34.6483842,-58.4782827)](https://www.google.com/maps/place/Toll+Parque+Avellaneda/@-34.6483842,-58.4782827,15z/data=!4m5!3m4!1s0x95bcc976fa19271d:0x114032996c02ca46!8m2!3d-34.6478475!4d-58.477942) in the _Perito Moreno_ highway. This geolocation matches the location provided in the [map](https://www.ausa.com.ar/documentos/AUSA-Mapa-Autopistas.pdf). This toll booth is much bigger than the one of _Peaje Alberti_, as it's right in the highway, and consists of [16 lanes](https://www.google.com/maps/@-34.6485245,-58.4775302,3a,82.3y,306.63h,84.59t/data=!3m6!1e1!3m4!1s0t2jEnNc2pbxYu3mgSMYiw!2e0!7i13312!8i6656) to enter the city and [17 lanes](https://www.google.com/maps/@-34.6473728,-58.4783124,3a,70.3y,140.7h,90.17t/data=!3m6!1e1!3m4!1s8HtLVelrUWM_-Lq3uKhZJw!2e0!7i13312!8i6656) to leave.

* `Dellepiane`: the _Dellepiane_ toll booth is located at [(-34.6476526,-58.4642902)](https://www.google.com/maps/@-34.6476526,-58.4642902,3a,75y,183.74h,83.19t/data=!3m7!1e1!3m5!1sAJy89f4OeGWzUY4j5jP_kA!2e0!6s%2F%2Fgeo2.ggpht.com%2Fcbk%3Fpanoid%3DAJy89f4OeGWzUY4j5jP_kA%26output%3Dthumbnail%26cb_client%3Dmaps_sv.tactile.gps%26thumb%3D2%26w%3D203%26h%3D100%26yaw%3D278.81256%26pitch%3D0%26thumbfov%3D100!7i13312!8i6656) in the _25 de Mayo_ highway. Just like with `Avellaneda`, it's geolocation matches the locationprovided in the [map](https://www.ausa.com.ar/documentos/AUSA-Mapa-Autopistas.pdf). What's particular about this toll booth is that it only consists of [8 lanes](https://www.google.com/maps/@-34.6476526,-58.4642902,3a,75y,183.74h,83.19t/data=!3m7!1e1!3m5!1sAJy89f4OeGWzUY4j5jP_kA!2e0!6s%2F%2Fgeo2.ggpht.com%2Fcbk%3Fpanoid%3DAJy89f4OeGWzUY4j5jP_kA%26output%3Dthumbnail%26cb_client%3Dmaps_sv.tactile.gps%26thumb%3D2%26w%3D203%26h%3D100%26yaw%3D278.81256%26pitch%3D0%26thumbfov%3D100!7i13312!8i6656) to leave the city, but none to enter, most likely due to its proximity to the Avellaneda toll booth.

* `Illia` and `Retiro`: as per the [map](https://www.ausa.com.ar/documentos/AUSA-Mapa-Autopistas.pdf), the _Retiro_ toll booth is located in the _President Arturo Umberto Illia_ highway. Contrary to what was mentioned about this two toll booths in the the [previous analysis](https://github.com/tulians/traffic/tree/master/descriptive#increment-in-traffic), given that there is no distinction between those two labels in the official map, they will be considered to be the same toll booth in this analysis. This toll booth has [16 lanes](https://www.google.com/maps/@-34.5752154,-58.3939207,3a,75y,97.32h,90.8t/data=!3m6!1e1!3m4!1sgu6cZza2fn1MaGwSQDCN8Q!2e0!7i13312!8i6656) to enter the city, and [13 lanes](https://www.google.com/maps/@-34.5753211,-58.3920502,3a,60y,297.07h,84.14t/data=!3m6!1e1!3m4!1syPX2FmTEXJDiDXbKJ_60lw!2e0!7i13312!8i6656) to leave.

* `Sarmiento` and `Salguero`: these two toll booths are the most recent of all, and are completely automatic, thus don't have any kind of barriers of physical toll booths. They rely on a framework that identifies via laser and RFID whether a given car is suscribed to the automatic toll booth pay a fine. Given the fact that this system was recently implemented, and that Google Maps' most up to date photograph is from [2014](https://www.google.com/maps/@-34.5720142,-58.4003746,3a,75y,86.66h,84.34t/data=!3m6!1e1!3m4!1s4EUI6eAipzhLxajyKJyH3Q!2e0!7i13312!8i6656) there is no information on the amount of lanes the system uses, but judging for the [way it is explained in a local newspaper](https://www.clarin.com/brandstudio/autopistas-barreras-funcionan-beneficios_0_BFyjtPTT7.html) the lasers most likely take the width of the highway, which is [4 lanes](https://www.google.com/maps/@-34.572059,-58.4002728,3a,75y,89.44h,76.27t/data=!3m6!1e1!3m4!1sUBDmnfT7MIlSI-IaUNA8rg!2e0!7i13312!8i6656) to enter the city and [4 lanes](https://www.google.com/maps/@-34.5717317,-58.4002346,3a,75y,318.34h,75.16t/data=!3m7!1e1!3m5!1sB5bOs_1b8Kgeal35aCFRdw!2e0!6s%2F%2Fgeo3.ggpht.com%2Fcbk%3Fpanoid%3DB5bOs_1b8Kgeal35aCFRdw%26output%3Dthumbnail%26cb_client%3Dmaps_sv.tactile.gps%26thumb%3D2%26w%3D203%26h%3D100%26yaw%3D9.781906%26pitch%3D0%26thumbfov%3D100!7i13312!8i6656) to leave.

##### Assumptions
* As you can see from the above links the amount of toll booths per lane was manually counted using Google Maps. However, these amounts are not fixed, and depend on date and time, in order to accomodate the service to the incoming volume of vehicles. The are no official communications from AUSA on how those changes are performed, so for the sake of this analysis the amount of toll booths to use would be the sum of those going in and those going out of the city. This is due to the fact that the information provided is aggregated to a level that does not provide visibility on the direction of the vehicles.

* Building on this last point, it will be assumed the vast majority of the traffic during the morning peak hour is heading towards the city, while the traffic during the afternoon peak hour is leaving the city.

* All toll booths in each of the plazas is considered to be the same in terms of technology and service time. The only difference that will be considered would be that of automatic and manual toll booths.

* Service time is considered independent of the length of the queue.

#### Estimation of traffic intensity per toll booth
In the previous section we discussed the need of computing the arrival rate $\lambda$ and service rate $\mu$ in order to know the traffic intensity $\rho$. The former can be derived directly from the information provided by the dataset, given that each of its records indicates the amount of vehicles that arrived and went through the toll booths per hour. However, in order to estimate $\mu$ assumptions have to be raised, or a field measurement has to be performed. Both approaches will be performed during this analysis.

##### Traffic intensity
Going back to what was mentioned at the beginning of this section, traffic intensity was defined as the ratio between the arrival rate $\lambda$ and the service rate $\mu$, so that $\lambda < \mu$. That condition ensures the system is stable. However, it only accounts for the case of a single server, while in this case  we have $S$ toll booths per plaza. This yields a system stability condition of $\lambda < S\mu$, thus defining $\rho$ as $\rho = \frac{\lambda}{S\mu}$. Following the third assumption in the assumptions section, as all toll booths are considered equal, we can express the total capacity of the system by multipying an individual toll booth capacity by the amount of toll booths in a toll booth plaza.

The next two subsections will be focused on the _Alberti_ toll booth plaza given that it's a toll booth from which we count with real information about service time $\mu$. The amount of vehicles that arrive on each hour to the toll booth, as shown in Figure 4, is computed considering recent information from year 2019. Additionally, only the _cars_ volume will be considered for the mentioned sections, as the analysis can be then extended to the least frequent vehicle types.

```{r albertivehiclesperhour, echo=FALSE}
years_to_filter_by <- c(2019) # 2014:2019
# Filtering only for Alberti information, on the years where there is more
# recent information (which is from 2019 onwards), and only for the top 2
# most frequent payment methods.
toll_booth_ff <- unified_ff %>% as_tibble() %>%
  filter (
    year_ %in% years_to_filter_by
    & toll_booth_name == "Alberti"
    & payment_method %in% c("Automatic", "Cash")
    & vehicle_type == "Car"
    & day_name == "Saturday"
  )
# We'll need to know the amount of days that our dataset contains, as further
# below it will be used to compute the amount of vehicles per hour, and each
# hour is present in every day.
amount_of_days <- toll_booth_ff %>%
  distinct (
    year_,
    month_,
    day_
  ) %>%
  nrow()

payments <- toll_booth_ff %>%
  group_by (
    payment_method,
    start_hour
  ) %>% 
  summarise (
    amount = sum(amount) / amount_of_days
  )

# Average hourly payments performed by vehicles that arrive at toll booths.
payments_per_hour <- payments %>%
  group_by (
    start_hour
  ) %>%
  summarise (
    amount = sum(amount)
  )

ggplot(data = payments_per_hour,
       aes(x = substr(start_hour, 1, 2), y = amount, group = 1)) +
  geom_line(linetype = "dashed") +
  geom_point(color = "blue") +
  labs(x = "Hour of day",
       y = "Volume of vehicles",
       title = 
         "Hourly average volume of cars in the Alberti toll booth plaza",
       caption = "Figure 4") +
  theme_minimal()

# Number of servers.
S <- 5
# System utilization.
rho <- 0.9
# Arrival rate.
lambda <- mean(payments_per_hour$amount)
# Compute service rate from the utilization assumption and the arrival rate,
# for an individual toll booth.
mu <- lambda / (S * rho)
```

##### Assumption of 90% utilization
An initial approach to the estimation of time-spent on queues would be to assume that toll booths are operating at 90% of their capacity. It actually makes sense to think that toll booth plazas were designed to be a stable system, due to the fact that even though long queues happen, and frequently during peak hours, they are eventually served up to the point that there's no queue left. In this scenario, each toll booth at the _Alberti_ toll booth plaza is able to serve up to `r mu` vehicles in an hour. This figure comes from computing $\mu = \frac{\lambda}{S\rho}$ where $\lambda$ is equal to the `r round(lambda, 2)` vehicles per hour, the average of the amount of vehicles per hour shown in Figure 4, the number of servers $S$ is `r S`, and the utilization/traffic intensity $\rho$ is $90\%$. This result means that in order for the system (toll booth plaza) to be operating at 90% of its capacity, each server (toll booth) needs to service at least `r round(mu, 2)` vehicles per hour. Summing up each server contribution, `r round(S * mu, 2)` vehicles can be serviced in an hour by this system. Servicing `r round(S * mu, 2)`  vehicles in an hour means that on average `r round(S * mu / 60, 2)` vehicles are serviced per minute in a toll booth plaza, regardless of the toll booth payment method. 

```{r effectofautomatictollbooths, echo=FALSE}
automatic_payments <- payments %>%
  group_by (
    start_hour
  ) %>%
  summarise (
    percentage = sum(amount[payment_method == "Automatic"]) / sum(amount)
  )
```

Although this number may seem high, it's important to mention that it includes the impact from automatic toll booths, which can service more vehicles that manual toll booths. For the concrete case of the _Alberti_ toll booth plaza, automatic payments constitute `r round(mean(automatic_payments$percentage) * 100, 2)`% of the payments volume. The specific percentages for each our are detailed in Figure 5.

```{r utilizationbreakdown, echo=FALSE}
ggplot(data = automatic_payments,
       aes(x = substr(start_hour, 1, 2), 
           y = percentage, 
           group = 1)) +
  geom_line(linetype = "dashed") +
  geom_point(color = "red") +
  labs(x = "Hour of day",
       y = "Percentage of automatic payments",
       title = "Percentage of cars going through automatic toll booths",
       caption = "Figure 5") +
  theme_minimal()

payments_per_hour <- payments %>%
  group_by (
    start_hour, 
    payment_method
  ) %>%
  summarise (
    amount = sum(amount)
  )

payment_methods_lambdas <- payments %>%
  group_by (
    payment_method
  ) %>%
  summarise (
    lambda = mean(amount)
  )

automatic_tolls <- 5

mu_manual <- payment_methods_lambdas[
  payment_methods_lambdas$payment_method == "Cash", ]$lambda / 
  ((S - automatic_tolls) * rho)
mu_automatic <- payment_methods_lambdas[
  payment_methods_lambdas$payment_method == "Automatic", ]$lambda / 
  (automatic_tolls * rho)
```

If we were to break down the service rate per payment method, we should expect to see faster service time for automatic toll booths, that could account for a high percentage of the almost `r round(S * mu / 60, 2)` vehicles served per minute. Performing such break down yields `r round((S - automatic_tolls) * mu_manual / 60, 2)` vehicles services by minute in manual payment toll booths, and `r round(automatic_tolls * mu_automatic / 60, 2)` vehicles services by minute in automatic payment toll booths. Even though the service rate for manual toll booths is higher than that of automatic toll booths, it must be taken into account that there are more toll booths with manual payment methods that booths with automatic ones. For the particular case of the _Alberti_ toll booth plaza, an approximate of `r automatic_tolls` toll booths are automatic, from a total of `r S`. This shows that even with just `r round(100 * automatic_tolls / S, 2)`% of the toll booths being automatic in this plaza, you can service `r round(mean(automatic_payments$percentage) * 100, 2)`% of the incoming traffic, as it was mentioned previously.

###### Characterization of the M/M/S system
Previously a traffic intensity $\rho$ of $90\%$ was assumed, and by doing so a realistic service rate `r round((S - automatic_tolls)* mu_manual / 60, 2)` vehicles per minute in manual toll booths and `r round(automatic_tolls * mu_automatic / 60, 2)` vehicles per minute in automatic toll booths was obtained.

The system will be modeled as an M/M/S queuing model, where the first *M* stands for a Poisson distributed arrival pattern of vehicles. From here is that we derive $\lambda$, the mean of such distribution. The second *M* stands for an exponential distribution of the service rate $\mu$. Lastly, S stands for the number of servers, in this case toll booths per toll booth plaza, with a First In - First Out discipline. Summing everything together, the system will be considered stable if $\lambda < S\mu$, as previously mentioned.

```{r characteristics, echo=FALSE}
# Probability of having no units in the system (idle system).
p0_ <- function(
  N, # Number of servers.
  rho # Utilization of the system.
) {
  n <- 0:(N-1)
  1 / (
    sum((rho)^n / factorial(n)) + (rho^N) / (factorial(N) * (1 - (rho / N)))
  )
}

# Probability of having n units in the system. This means having `n` vehicles
# arriving at the same time, one to each toll booth. 
pn <- function(
  n, # Amount of vehicles in the system.
  N, # Number of servers.
  rho # Utilization of the system.
) {
  if(!n) {
    p0_(N, rho)
  } else if((n - 1) == 0) {
    (rho / n) * p0_(N, rho) 
  } else {
    pn(n - 1, N, rho)
  }
}

# Average number of units in the queue.
Uq <- function (
  N, # Number of servers.
  rho # Utilization of the system.
) {
  p0_(N, rho) * ((rho^N) / factorial(N)) * (rho / N) / (1 - (rho / N))^2
}

# Average number of units in the system.
Us <- function (
  N, # Number of servers.
  rho # Utilization of the system.
) {
  rho + Uq(N, rho)
}

# Average time waiting in a queue.
Wq <- function (
  N, # Number of servers.
  rho, # Utilization of the system.
  lambda # Arrival rate.
) {
  Uq(N, rho) / lambda
}

# Average time waiting in the system.
Ws <- function (
  N, # Number of servers.
  rho, # Utilization of the system.
  lambda, # Arrival rate.
  mu # Service rate.
) {
  Wq(N, rho, lambda) + (1 / mu)
}
```

###### Probability of N vehicles arriving at a given time
Traffic intensity $\rho$ can be used to determine the probability of having no vehicles queuing in the system at a given moment of time, and is written as $P_0 = \frac{1}{\sum_{n = 0}^{N - 1}\frac{\rho^n}{n!}+\frac{\rho^N}{N!(1-\frac{\rho}{N})}}$, where $N$ is the number of toll booths $S$. Given this definition of $P_0$, the analogoues $P_n$, which would be the probability of having $n$ units in the system, is defined as $P_n = \left ( \frac{\rho}{n} \right ) P_{n-1}$. With our assumption of $90\%$ utilization the probability of having no vehicles in the system is `r round(100 * pn(0, S, rho), 2)`, while the probability of having $S$ vehicles arriving at the $S$ toll booths at the exact same time to be served is `r round(100 * pn(S, S, rho), 2)`.

###### Average number of units in queues
Using the probability of having an empty queue $P_0$ we can derive the average queue length. This metric will then be used to estimate the average waiting time in queues. As this are average times, they will take into account those times where there are no vehicles queuing, and times where there are long queues. For the case of $S$ servers, the average queue length is defined as $U_q(N, \rho) = P_0\frac{\rho^{N+1}}{N!N}\left [ \frac{1}{\left (1 - \frac{\rho}{N} \right )^2} \right ]$, and has an approximate value of `r Uq(S, rho)`. This value is actually very small, and could be rounded to $0$, and can be interpreted as arriving vehicles not having to queue for going through a toll booth.

###### Average waiting time for units in queues
The $U_q(N,\rho)$ metric can be reused to define the time spent waiting on queues as $W_q(N,\rho,\lambda) = U_q/\lambda$. The units of this metric are hours, and for this particular case it's value is `r Wq(S, rho, lambda)`, again very close to $0$. This result goes in tandem with the results from the average number of vehicles per queue, as not having to queue behind other vehicles means not spending that time on queues.

###### Partial conclusions for this analysis
The two previous calculations of average number of units in queues and average waiting time in queues shown that on average vehicles shouldn't wait for going through toll booths. However, there are moments of time during the day (peak hours) were it's a fact that's not the case.

```{r timeseries, echo=FALSE}
avellaneda_ts <- toll_booth_ff %>%
  filter (
    year_ > 2015
  ) %>%
  group_by (
    year_,
    month_,
    day_,
    start_hour
  ) %>%
  summarise (
    x = sum(amount)
  )

y <- avellaneda_ts$x / max(avellaneda_ts$x)
adf.test(y, alternative = "stationary")
# The p-value is smaller than 0.01, thus smaller then 0.05. The p-value is a
# conditional probability that the mean of the sample is greater different than
# the one in the null hypothesis H0, which in this case is the series is not
# stationary. More context on the warning:
# https://stackoverflow.com/questions/22031954/how-to-make-adf-test-print-more-precise-p-value-in-r
```

#### Estimation of service rate from empiric measurements
In the previous section the value of $\mu$ derived after assuming 90% utilization of the system. In order to know if the system is actually performing at such percentage or if it's actually a higher or lower one, empiric measurements in real toll booths were performed.

```{r realsample, echo=FALSE}
datasets_dir <- "../datasets/sources"
attention <- data.frame (
  read.csv (
    file = file.path(datasets_dir, "attention.csv"), 
    header = T, 
    dec = ".",
    stringsAsFactors = T
  )
)

# Observations were measured in seconds. Given that the volume of vehicles
# paying with cash is not the exact same volume as those paying automatically,
# a weighted average of both payments methods is used to compute both the 
# arrival and service rate.
p <- mean(automatic_payments$percentage)
# Arrival rate.
lambda_automatic <- mean(
  payments$amount[payments$payment_method == "Automatic"])
lambda_manual <- mean(payments$amount[payments$payment_method == "Cash"])
lambda <- lambda_automatic + lambda_manual
# Service rate. Given that the volume of vehicles paying with cash is not the 
# exact same volume as those paying automatically, a weighted average of 
# payments methods is used to compute the service rate.
mu_automatic <- 1 / (mean(attention$time[attention$type == "automatic"]) / 3600)
mu_manual <- 1 / (mean(attention$time[attention$type == "manual"]) / 3600)
mu <- p * mu_automatic + (1 - p) * mu_manual
# Using the empirically computed service rate, the utilization is recomputed.
rho <- lambda / (S * mu)
```

