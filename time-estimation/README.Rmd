---
title: "Estimation of time-spent on AUSA toll booths"
author: "Julián Ailán"
params:
  date: "!r Sys.Date()"
output:
  github_document:
    toc: yes
    pandoc_args: --webtex
---

```{r setupandrequiredpackages, include=FALSE, fig.align="center"}
knitr::opts_chunk$set(echo = TRUE)

rm(list = ls()); gc();

packages_to_include <- c (
  "dplyr", "tibble", "ggplot2", "ff", "reshape2", "tseries", "ggrepel"
)

lapply (
  packages_to_include, # From this list ...
  require, # ... include them as packages.
  character.only = T
)

theme_set(theme_minimal() + theme(legend.position = 'bottom'))

rm(packages_to_include)
```

### Objective
This project consists on estimating time-spent by drivers on AUSA toll booths in Buenos Aires highways. Currently users of these highways experience excessive amount of time waiting to go through toll booths on peak hours. In addition to estimating this metric, an analysis of whether contextual variables like toll-booth fee or oil prices have an impact on the behavior and amount of users commuting through these highways.

### Joining the traffic dataset with the oil dataset
The `traffic.csv` dataset previously analized [here](https://github.com/tulians/traffic/tree/master/descriptive) has a file size of approximately 562MB, while the `oil_prices.csv` dataset is only 11.2KB. We'll be merging both files in an inner join fashion, using the year and month columns via the [`merge()`](https://www.rdocumentation.org/packages/base/versions/3.6.0/topics/merge) function. As a result of this merge each existing row in `traffic.csv` will be repeated 4 times, one per each oil type, thus taking the final, merged, dataset to an approximate size of 2.2GB.

R requires that variables are stored in RAM in its entirety, so managing a dataframe this big could be imposible for some machines if no alternate processing is performed. For this reason is that the [`ff`](https://cran.r-project.org/web/packages/ff/index.html) package will be used.

```{r readingunifiedfile, echo=FALSE}
datasets_dir <- "../datasets"

# Directory where `ff` stores temporary files. Take into account temporary files
# will fill up this directory through time. Make sure to delete them once in a
# while.
options (
  fftempdir = file.path(datasets_dir, "tmp")
)

unified_ff <- read.csv.ffdf (
  file = file.path(datasets_dir, "unified.csv")
)

rm(datasets_dir)
```

### Time spent waiting on queues estimation
It's usual to see vehicles queuing in Buenos Aires' toll booth plazas at peak hours. More than 1.5M vehicles enter the city each day, most of which are people commuting to work. In this context toll booths regularly feature queues that extend through kilometers in highways. The objective of this section is to accurately estimate the average time a given driver waits in order go through the toll booth.

In order to achieve this goal we need to have concrete figures of both the rate at which cars arrive to the toll booths $\lambda$, and also the rate at which cars can be serviced $\mu$, meaning, the amount of cars that go through the toll booth at a given period of time. Both of the rates would be averages, as they will be considering times where there is a long queue, as well as times where there's no queue at all. The $\rho=\lambda/\mu$ ratio, known as traffic intensity, will help us identify the average behavior of the queue, given that if $\rho < 1$ there is a finite probability that the queue can be handled by the booth; on the other hand if $\rho \geq 1$ the queue length will become longer and longer without limit up to infinity (at least in theoretical terms).

Given that we have information of traffic flow along several toll booths, we'll use it to derive these two coefficients, and find the value of $\rho$ for each of the toll booth plazas. Depending on the dimension of this ratio, we'll need to compute waiting time one way or another. More details on this calculations will be given in future sections.

#### Important considerations
##### Toll booth plaza naming, geolocation, and amount of toll booths per plaza
Up to now we've been working with the dataset without validating whether all the information provided was accurate. However, there were mentions in the [previous section](https://github.com/tulians/traffic/tree/master/descriptive#increment-in-traffic) to strange patterns in data. In this section we'll validate that every toll booth plaza name provided in the dataset actually exists, and also where it's located geographically. To perform this validation we'll use a [map](https://www.ausa.com.ar/documentos/AUSA-Mapa-Autopistas.pdf) provided by the same company the information is about.

* `Alberdi`: _Juan Bautista Alberdi_ is an avenue located at [(-34.6429211, -58.4910398)](https://www.google.com/maps/@-34.6429211,-58.4910398,18z) which provides a way to enter the _Perito Moreno_ highway. However, there is no toll booth in such entrance. Looking at the previously mentioned [map](https://www.ausa.com.ar/documentos/AUSA-Mapa-Autopistas.pdf), we can validate there is no toll booth sign in the entrance. However, there is such a sign in an actual toll booth in the _25 de Mayo_ highway, located at [(-34.6252954,-58.4022763)](https://www.google.com/maps/@-34.6252954,-58.4022763,17z), under the name of _Peaje Alberti_ (mind that they differ in one character, as the latter has a _t_ instead of a _d_). Given this context, most likely the information we see for _Alberdi_ corresponds to _Alberti_, as the latter is the one that has a toll booth, while the former does not. Something important to mention about this toll booth is that it counts with [3 lanes](https://www.google.com/maps/@-34.6253084,-58.399961,3a,75y,296.16h,87.96t/data=!3m7!1e1!3m5!1szK1wuTFcAlvJddIHqUlZWw!2e0!6s%2F%2Fgeo0.ggpht.com%2Fcbk%3Fpanoid%3DzK1wuTFcAlvJddIHqUlZWw%26output%3Dthumbnail%26cb_client%3Dmaps_sv.tactile.gps%26thumb%3D2%26w%3D203%26h%3D100%26yaw%3D317.5315%26pitch%3D0%26thumbfov%3D100!7i13312!8i6656) to enter the city, and [2 lanes](https://www.google.com/maps/@-34.6257901,-58.4001986,3a,75y,84.02h,99.26t/data=!3m6!1e1!3m4!1sTeolsLKGK9ckp3WVWxFLQg!2e0!7i13312!8i6656) to leave. For the sake of the code, I'll keep on using the `Alberdi` label, but everything will be computed with _Peaje Alberti_ in mind.

* `Avellaneda`: the _Parque Avellaneda_ toll booth is located at [(-34.6483842,-58.4782827)](https://www.google.com/maps/place/Toll+Parque+Avellaneda/@-34.6483842,-58.4782827,15z/data=!4m5!3m4!1s0x95bcc976fa19271d:0x114032996c02ca46!8m2!3d-34.6478475!4d-58.477942) in the _Perito Moreno_ highway. This geolocation matches the location provided in the [map](https://www.ausa.com.ar/documentos/AUSA-Mapa-Autopistas.pdf). This toll booth is much bigger than the one of _Peaje Alberti_, as it's right in the highway, and consists of [16 lanes](https://www.google.com/maps/@-34.6485245,-58.4775302,3a,82.3y,306.63h,84.59t/data=!3m6!1e1!3m4!1s0t2jEnNc2pbxYu3mgSMYiw!2e0!7i13312!8i6656) to enter the city and [17 lanes](https://www.google.com/maps/@-34.6473728,-58.4783124,3a,70.3y,140.7h,90.17t/data=!3m6!1e1!3m4!1s8HtLVelrUWM_-Lq3uKhZJw!2e0!7i13312!8i6656) to leave.

* `Dellepiane`: the _Dellepiane_ toll booth is located at [(-34.6476526,-58.4642902)](https://www.google.com/maps/@-34.6476526,-58.4642902,3a,75y,183.74h,83.19t/data=!3m7!1e1!3m5!1sAJy89f4OeGWzUY4j5jP_kA!2e0!6s%2F%2Fgeo2.ggpht.com%2Fcbk%3Fpanoid%3DAJy89f4OeGWzUY4j5jP_kA%26output%3Dthumbnail%26cb_client%3Dmaps_sv.tactile.gps%26thumb%3D2%26w%3D203%26h%3D100%26yaw%3D278.81256%26pitch%3D0%26thumbfov%3D100!7i13312!8i6656) in the _25 de Mayo_ highway. Just like with `Avellaneda`, it's geolocation matches the locationprovided in the [map](https://www.ausa.com.ar/documentos/AUSA-Mapa-Autopistas.pdf). This toll booth is that it only consists of [8 lanes](https://www.google.com/maps/@-34.6476526,-58.4642902,3a,75y,183.74h,83.19t/data=!3m7!1e1!3m5!1sAJy89f4OeGWzUY4j5jP_kA!2e0!6s%2F%2Fgeo2.ggpht.com%2Fcbk%3Fpanoid%3DAJy89f4OeGWzUY4j5jP_kA%26output%3Dthumbnail%26cb_client%3Dmaps_sv.tactile.gps%26thumb%3D2%26w%3D203%26h%3D100%26yaw%3D278.81256%26pitch%3D0%26thumbfov%3D100!7i13312!8i6656) to leave the city, and [15 lanes](https://www.google.com/maps/@-34.6496524,-58.4653365,3a,75y,227.71h,85.06t/data=!3m6!1e1!3m4!1sHLTRXcFyEzF3xV6j9GIvRg!2e0!7i13312!8i6656) to enter.

* `Illia` and `Retiro`: as per the [map](https://www.ausa.com.ar/documentos/AUSA-Mapa-Autopistas.pdf), the _Retiro_ toll booth is located in the _President Arturo Umberto Illia_ highway. Contrary to what was mentioned about this two toll booths in the the [previous analysis](https://github.com/tulians/traffic/tree/master/descriptive#increment-in-traffic), given that there is no distinction between those two labels in the official map, they will be considered to be the same toll booth in this analysis. This toll booth has [16 lanes](https://www.google.com/maps/@-34.5752154,-58.3939207,3a,75y,97.32h,90.8t/data=!3m6!1e1!3m4!1sgu6cZza2fn1MaGwSQDCN8Q!2e0!7i13312!8i6656) to enter the city, and [13 lanes](https://www.google.com/maps/@-34.5753211,-58.3920502,3a,60y,297.07h,84.14t/data=!3m6!1e1!3m4!1syPX2FmTEXJDiDXbKJ_60lw!2e0!7i13312!8i6656) to leave.

* `Sarmiento` and `Salguero`: these two toll booths are the most recent of all, and are completely automatic, thus don't have any kind of barriers of physical toll booths. They rely on a framework that identifies via laser and RFID whether a given car is suscribed to the automatic toll booth pay a fine. Given the fact that this system was recently implemented, and that Google Maps' most up to date photograph is from [2014](https://www.google.com/maps/@-34.5720142,-58.4003746,3a,75y,86.66h,84.34t/data=!3m6!1e1!3m4!1s4EUI6eAipzhLxajyKJyH3Q!2e0!7i13312!8i6656) there is no information on the amount of lanes the system uses, but judging for the [way it is explained in a local newspaper](https://www.clarin.com/brandstudio/autopistas-barreras-funcionan-beneficios_0_BFyjtPTT7.html) the lasers most likely take the width of the lane drivers have to use to enter or leave the highway, this is, 2 lanes in total.

##### Assumptions
* As you can see from the above links the amount of toll booths per lane was manually counted using Google Maps. However, these amounts are not fixed, and depend on date and time, in order to accomodate the service to the incoming volume of vehicles. The are no official communications from AUSA on how those changes are performed, so for the sake of this analysis the amount of toll booths to use would be the sum of those going in and those going out of the city. This is due to the fact that the information provided is aggregated to a level that does not provide visibility on the direction of the vehicles.

* Building on this last point, it will be assumed the vast majority of the traffic during the morning peak hour is heading towards the city, while the traffic during the afternoon peak hour is leaving the city.

* All toll booths in each of the plazas is considered to be the same in terms of technology and service time. The only difference that will be considered would be that of automatic and manual toll booths.

* Service time is considered independent of the length of the queue.

* As the maximum dataset granularity is an interval of one hour, all transit for that hour will be considered from that hour only, meaning, it is assumed that no queues carry on from a previous time interval to the following one.

#### Estimation of traffic intensity per toll booth
In the previous section we discussed the need of computing the arrival rate $\lambda$ and service rate $\mu$ in order to know the traffic intensity $\rho$. The former can be derived directly from the information provided by the dataset, given that each of its records indicates the amount of vehicles that arrived and went through the toll booths per hour. In order to estimate $\mu$ a sample toll booth service time was taken from the _Alberti_ toll booth plaza. Additionally, only _cars_ volume will be taken into account, as sample consists only on cars measurements.

The next three section will consist on a detailed explanation of each of the three variables of $\rho = \frac{\lambda}{S\mu}$, with the objective of estimating the utilization $\rho$ of the _Alberti_ at each hour of the day.

##### Arrivals
At the moment of writing the most recent information the dataset holds is from January 2019. The rationale for using the most recent information to define the arrival rate is that the volume of vehicles going through toll booths steadily increased through the years, so using information from prior years can lower the average arrival volumes. Figure 4 shows the average amount of vehicles that arrive to the _Alberti_ toll booth per hour.

```{r albertivehiclesperhour, echo=FALSE}
years_to_filter_by <- c(2019)

# Filtering only for recent information (which is from 2019 onwards), and only 
# for the top 2 most frequent payment methods. The global information will be
# used in the next section.
toll_booth_ff <- unified_ff %>% as_tibble() %>%
  filter (
    year_ %in% years_to_filter_by
    & payment_method %in% c("Automatic", "Cash")
    & vehicle_type == "Car"
  )

# We'll need to know the amount of days that our dataset contains, as further
# below it will be used to compute the amount of vehicles per hour, and each
# hour is present in every day.
amount_of_days <- toll_booth_ff %>%
  distinct (
    year_,
    month_,
    day_
  ) %>%
  nrow()

payments <- toll_booth_ff %>%
  group_by (
    toll_booth_name,
    payment_method,
    start_hour,
    booths
  ) %>%
  summarise (
    # Divide by 4 as each row is repeated 4 times due to the oil dataset join.
    amount = 0.25 * sum(amount) / amount_of_days
  )

# Average hourly payments performed by vehicles that arrive at toll booths.
payments_per_hour <- payments %>%
  group_by (
    toll_booth_name,
    start_hour
  ) %>%
  summarise (
    amount = sum(amount)
  )

payments_alberti <- payments %>%
  filter (
    toll_booth_name == "Alberti"
  )

payments_per_hour_alberti <- payments_alberti %>%
  group_by (
    start_hour
  ) %>%
  summarise (
    amount = sum(amount)
  )

ggplot(data = payments_per_hour_alberti,
       aes(x = substr(start_hour, 1, 2), y = amount, group = 1)) +
  geom_line(linetype = "dashed") +
  geom_point(color = "blue") +
  labs(x = "Hour of day",
       y = "Volume of vehicles",
       title = 
         "Hourly average volume of cars in the Alberti toll booth plaza",
       caption = "Figure 4")

rm(years_to_filter_by, payments_per_hour_alberti, amount_of_days, toll_booth_ff)
```

The previous figure presents two peaks which correspond to the timeframes of 9am to 11am and 6pm to 8pm. It would be expected that the utilization of the system, length of the queues, and the time spent on them increases when approaching a peak hour. Figure 5 ilustrates the breakdown of the previously shown volume per payment method, which clearly indicates the peaks are mostly driven by users leaning towards the use of the automatic payment method.

```{r arrivalrate, echo=FALSE}
# Arrival rate.
lambda <- payments %>%
  group_by (
    toll_booth_name,
    start_hour,
    booths
  ) %>%
  summarise (
    arrival = sum(amount)
  )

ggplot(data = payments_alberti,
       aes(x = substr(start_hour, 1, 2), y = amount, group = payment_method)) +
  geom_line(aes(color = payment_method)) +
  labs(x = "Hour of day",
       y = "Volume of vehicles",
       title = "Hourly vehicle volume breakdown per payment method",
       caption = "Figure 5")

rm(payments_alberti)
```


##### Service time
The _Alberti_ toll booth plaza has a total of 5 toll booths, 2 of them for accessing the _25 de Mayo_ highway, and other 3 for leaving it. A sample of 70 observations of vehicles being serviced on this toll booth was taken on a Saturday, which yielded the distribution presenteed in Figure 6.

```{r attentionsample, echo=FALSE}
datasets_dir <- "../datasets/sources"
attention <- data.frame (
  read.csv (
    file = file.path(datasets_dir, "attention.csv"), 
    header = T, 
    dec = ".",
    stringsAsFactors = T
  )
)

ggplot(data = attention, 
       aes(x = time, fill = type)) + 
  geom_density(alpha = .3) +
  labs(x = "Service time (s)", 
       y = "Density",
       title = "Density of each payment method",
       caption = "Figure 6")

rm(datasets_dir)
```

The density function for the automatic payment method is more narrow than its manual counter part given that the latter could be impacted by many factors like the driver not having exact change prepared to pay, or the toll booth employee taking more or less time to service different clients. The average service time for the automatic payment method is `r mean(attention$time[attention$type == "automatic"])` seconds, while the average service time for manual payments is `r mean(attention$time[attention$type == "manual"])` seconds.

One characteristic of _Alberti_'s toll booths is they are both automatic and manual, so depending on the payment method of choosing of the driver, they can pay with cash or with an electronic tag. In summary, Figure 5 tells us there are moments of the day where automatic payments have more impact, while Figure 6 illustrates the densities of each payment method, and how service time differs between them. Such difference has to be taken into account when computing the service rate $\mu$ for the estimation of the traffic intensity $\rho$.

```{r servicerate, echo=FALSE}
# Observations were measured in seconds. Given that the volume of vehicles
# paying with cash is not the exact same volume as those paying automatically,
# a weighted average of both payments methods is used to compute both the 
# arrival and service rate.
share <- payments %>%
  group_by (
    toll_booth_name,
    start_hour
  ) %>%
  summarise (
    manual = sum(amount[payment_method == "Cash"]) / sum(amount),
    automatic = sum(amount[payment_method == "Automatic"]) / sum(amount)
  )

# Service rate. Given that the volume of vehicles paying with cash is not the 
# exact same volume as those paying automatically, a weighted average of 
# payments methods is used to compute the service rate.
avg_serving_time_automatic <- attention %>%
  filter (
    type == "automatic"
  ) %>%
  summarise (
    service = mean(time) / 3600
  )

avg_serving_time_manual <- attention %>%
  filter (
    type == "manual"
  ) %>%
  summarise (
    service = mean(time) / 3600
  )

mu <- share %>%
  group_by (
    toll_booth_name,
    start_hour
  ) %>%
  summarise (
    service = (avg_serving_time_automatic[[1]] * automatic +
                 avg_serving_time_manual[[1]] * manual)^-1
  )

mu_alberti <- mu %>%
  filter (
    toll_booth_name == "Alberti"
  )

rm(avg_serving_time_automatic, avg_serving_time_manual, share, attention,
   payments)
```

For this reason the service rate has to be expressed as a weighted sum which is function of the mean service times and its relative hourly weight. Such relation can be expressed as $\mu = \frac{1}{\alpha_it_a + \beta_it_m}$ where $\alpha_i$ indicates the percentage of vehicles paying with the automatic payment method at the hour $i$, and $\beta_i$ indicates the percentage of vehicles paying manually at the hour $i$, or $\beta = 1 - \alpha$. The resulting hourly values of $\mu$ are presented in Figure 7

```{r serviceperhour, echo=FALSE}
ggplot(data = mu_alberti, 
       aes(x = substr(start_hour, 1, 2), y = service, group = 1)) +
  geom_line(linetype = "dashed") +
  geom_point(color = "blue") +
  labs(x = "Hour of the day", 
       y = "Amount of vehicles",
       title = "Vehicles served per hour per toll booth",
       caption = "Figure 7")

rm(mu_alberti)
```

##### Traffic intensity
Traffic intensity is defined as the ratio between the arrival rate $\lambda$ and the service rate $\mu$, so that $\lambda < \mu$. That condition ensures the system is stable. However, it only accounts for the case of a single server, while in this case  we have $S$ toll booths per plaza. This yields a system stability condition of $\lambda < S\mu$, thus defining $\rho$ as $\rho = \frac{\lambda}{S\mu}$. Following the third assumption in the assumptions section, as all toll booths are considered equal, we can express the total capacity of the system by multipying an individual toll booth capacity by the amount of toll booths in a toll booth plaza.

Given the definitions of $\lambda$ and $\mu$ in the prior two sections, the utilization of the _Alberti_ toll booth plaza can be described by Figure 8, which presents the percentage of utilization of the 5 toll booths in such plaza. The moments where the toll booth plaza is mostly used are peak hours, with 10am having a 73.5% utilization, and 6pm with 72% utilization.

```{r realsample, echo=FALSE}
# Using the empirically computed service rate, the utilization is recomputed.
rho <- data.frame (
  toll_booth_name = lambda$toll_booth_name,
  start_hour = lambda$start_hour,
  arrival = lambda$arrival,
  service = mu$service,
  booths = lambda$booths,
  utilization = lambda$arrival / (lambda$booths * mu$service)
)

rho_alberti <- rho %>%
  filter (
    toll_booth_name == "Alberti"
  )

ggplot(data = rho_alberti, 
       aes(x = substr(start_hour, 1, 2), y = 100 * utilization, group = 1)) +
  geom_line(linetype = "dashed") +
  geom_point(color = "blue") +
  labs(x = "Hour of the day", 
       y = "Percentage of toll booth plaza utilization",
       title = "Hourly utilization of Alberti toll booth plaza",
       caption = "Figure 8")

rm(lambda, mu)
```

##### Characterization of the M/M/S system
The system will be modeled as an M/M/S queuing model, where the first *M* stands for a Poisson distributed arrival pattern of vehicles. From here is that we derive $\lambda$, the mean of such distribution. The second *M* stands for an exponential distribution of the service rate $\mu$. Lastly, S stands for the number of servers, in this case toll booths per toll booth plaza, with a First In - First Out discipline. Summing everything together, the system will be considered stable if $\lambda < S\mu$, as previously mentioned.

```{r characteristics, echo=FALSE}
# Individual rho calculation.
rho_ <- function (
  S, # Number of servers.
  lambda, # Arrivals to the system.
  mu # System service rate.
) {
  (lambda / mu) ^ S / factorial(S)
}

# Probability of having no units in the system (idle system).
p0_ <- function (
  S, # Number of servers.
  lambda, # Arrivals to the system.
  mu # System service rate.
) {
  r <- rho_(0:S, lambda, mu)
  p0 <- 1 / (sum(r[1:(S-1)]) + (r[S] / (1 - (lambda / mu) / S)))
  ifelse (
    (p0 > 1) | (p0 < 0), 
    0, 
    p0
  )
}

# Probability of waiting for an arriving customer.
pd <- function (
  S, # Number of servers.
  lambda, # Arrivals to the system.
  mu # System service rate.
) {
  ifelse (
    (lambda / mu / S) > 1, 
    1, 
    1 - p0_(S, lambda, mu) * sum(rho_(0:(S-1), lambda, mu))
  )
}

# Average number of units in the queue.
Lq <- function (
  S, # Number of servers.
  lambda, # Arrivals to the system.
  mu # System service rate.
) {
  r <- lambda / mu / S
  ifelse (
    r > 1,
    Inf,
    p0_(S, lambda, mu) * rho_(S, lambda, mu) * r / (1 - r)^2
  )
}

# Average number of units in the system.
Ls <- function (
  S, # Number of servers.
  lambda, # Arrivals to the system.
  mu # System service rate.
) {
  Lq(S, lambda, mu) + (lambda / mu)
}

# Average time waiting in a queue.
Wq <- function (
  S, # Number of servers.
  lambda, # Arrivals to the system.
  mu # System service rate.
) {
  Lq(S, lambda, mu) / lambda
}

# Average time waiting in the system.
Ws <- function (
  S, # Number of servers.
  lambda, # Arrivals to the system.
  mu # System service rate.
) {
  Wq(S, lambda, mu) + (1 / mu)
}
```

###### Probability of an idle system.
Traffic intensity $\rho$ can be used to determine the probability of having no vehicles queuing in the system at a given moment of time, and is written as $P_0(S, \rho) = \frac{1}{\sum_{n = 0}^{S - 1}\frac{\rho^n}{n!}+\frac{\rho^S}{S! \left (1-\frac{\rho}{S} \right)}}$, where $S$ is the number of toll booths. This definition of $P_0$ is used as a building block for the metrics that follow.

###### Average number of units in queues
The average queue length can be derived using the probability of having an empty queue $P_0$. For the general case of $S$ servers, the average queue length is defined as $L_q(S, \rho) = P_0\frac{\rho^{S+1}}{S!S}\left [ \frac{1}{\left (1 - \frac{\rho}{S} \right )^2} \right ]$.

###### Average waiting time for units in queues
The $L_q(S,\rho)$ metric can be reused to define the time spent waiting on queues as $W_q(S,\rho,\lambda) = L_q(S, \rho)/\lambda$, and it units are hours, given that $\lambda$ is defined in hours for this particular analysis.

###### Example application for the 10am peak hour
```{r metricsatpeak, echo=FALSE}
index <- which(rho_alberti$utilization == max(rho_alberti$utilization))
lambda_max <- rho_alberti$arrival[index]
mu_max <- rho_alberti$service[index]
S <- mean(rho_alberti$booths)

characteristics <- function (
  S, # Number of servers.
  lambda, # Arrivals to the system.
  mu # System service rate.
) {
  c (
    S = S,
    Lq = Lq(S, lambda, mu),
    Wq = Wq(S, lambda, mu) * 3600,
    P0 = p0_(S, lambda, mu) * 100,
    PD = pd(S, lambda, mu) * 100,
    rho = min(lambda / mu / S, 1) * 100
  )
}

metrics <- data.frame (
  as.list(characteristics(S, lambda_max, mu_max))
)

rm(rho_alberti, S)
```
In a previous section it was shown that the highest utilization of the _Alberti_ toll booth plaza happens during the interval of time between `r index` and `r index + 1`, with a percentage of utilization $\rho$ of `r round(metrics$rho, 2)`%. That number is obtained by computing $\rho = \frac{\lambda}{S\mu}$. For this particular set of metric values, the average length of the queue $L_q$ would be `r round(metrics$Lq, 2)` vehicles, the average time spent in a queue $W_q$ would be `r round(metrics$Wq, 2)` seconds, the probability of arriving at an empty queue $P_0$ would be `r round(metrics$P0, 2)`%, and the probability of having to wait to go throught he toll booth $P_d$ would be `r round(metrics$PD, 2)`%, for the mentioned utilization of `r round(metrics$rho, 2)`%.

###### Variable servers number for a fixed point in time
The previous example has such performance metrics with the assumption that the _Alberti_ toll booth plaza is servicing users with 5 toll booths. The table shown below exemplifies the behavior of the toll booth plaza on its entirety for scenarios where the amount of servers is different than 5. 

```{r moreexamples, echo=FALSE}
rm(index)
metrics <- data.frame (
  do.call("rbind", lapply(1:10, characteristics, lambda_max, mu_max))
)
metrics
```

As shown in the table above, any amount of servers lower than 4 toll booths will result in an infinite queue, as both $L_q$ and $W_q$ are infinite due to the fact $rho \geq 1$. Looking at the values of $\rho$, the biggest step in diminishing utilization appears when moving from 4 servers to 5 servers. As shown in Figure 9, there is a drop of 18.4 percentual points in utilization when a fifth toll booth is added to the plaza. This is the same amount of servers the _Alberti_ toll booth plaza has today, and is a critical step in the design of a toll booth plaza.

```{r serversdiff, echo=FALSE}
rho_diff <- data.frame (
  servers = 2:nrow(metrics),
  step = abs(diff(metrics$rho))
)

ggplot(data = rho_diff, 
       aes(x = servers, y = step, label = round(step, 1))) +
  geom_line(linetype = "dashed") +
  geom_point(color = "blue") +
  geom_text_repel(
    point.padding = .6, 
    nudge_x = .15,
    nudge_y = .5,
    arrow = arrow(length = unit(0.015, "npc"))
  ) +
  labs(x = "Amount of servers", 
       y = "Percentual points difference in utilization",
       title = "Impact on utilization of adding extra servers",
       caption = "Figure 9")

rm(metrics, rho_diff, lambda_max, mu_max)
```

###### Minimum amount of servers needed per hour of day
The previous section illustrated the importance of having a minimum amount of servers available for the system to be stable (meaning $\lambda/\mu < 1$). As that section was specific for the 10am - 11am time period, this section extends it to the remaning intervals of time during the day.

```{r utilizationperhour, echo=FALSE}
servers_required <- rho %>%
  group_by (
    toll_booth_name,
    start_hour
  ) %>%
  summarise (
    amount = ceiling(arrival / service)
  )

servers_required_alberti <- servers_required %>%
  filter (
    toll_booth_name == "Alberti"
  )

ggplot(data = servers_required_alberti, 
       aes(x = substr(start_hour, 1, 2), y = amount, group = 1)) +
  geom_line(linetype = "dashed") +
  geom_point(color = "blue") +
  labs(x = "Hour of day", 
       y = "Amount of servers",
       title = "Minimal amount of servers to avoid infinite queues",
       caption = "Figure 10")
```

Figure 10 describes the amount of servers needed for the _Alberti_ toll booth in order to avoid infinite queues. Around 10am a recommended amount of 4 toll booths is indicated, which is consistent with the results shown in the table above, where the change from 3 to 4 servers droped the length of the queue and waiting time from infinite to a concrete number. Having said that, the amount of servers displayed in Figure 10 is only the minimum amount required to have a stable system, but not one that minimizes queue length or waiting times.

### Characterization of each AUSA's toll booth plazas
Building on the methodologies and calculation of traffic intensity and time spent on queues, this section is going to extend such analysis to the whole of AUSA toll booth plazas.

#### Volume of vehicles going through each toll booth plaza
The amount of vehicles that each toll booth plaza services is the building block for futher design decisions with respect to amount of toll booths, and thus average time-spent on queues. Figure 11 describes the traffic evolution during the day for each toll booth plaza. In terms of behavior, each of the toll booth plazas is subject to the same trend, but with different orders of magnitude.

```{r trafficperbooth, echo=FALSE}
ggplot(data = payments_per_hour,
       aes(x = substr(start_hour, 1, 2), y = amount, group = toll_booth_name)) +
  geom_line(aes(color = toll_booth_name)) +
  labs(x = "Hour of day",
       y = "Volume of vehicles",
       title = 
         "Hourly average volume of cars in the Alberti toll booth plaza",
       caption = "Figure 11") +
  scale_y_continuous(trans = "log10")

rm(payments_per_hour)
```

#### Utilization of each toll booth plaza throughout the day
Interpreting the arrivals information on Figure 11 as the arrival rate $\lambda$, and reusing the service rate information obtained empirically, an estimation of the hourly utilization $\rho$ of each toll booth plaza is presented in Figure 12. The top 3 more utilized toll booth plazas are: Avellaneda with a maximum average utilization of 81.5%, Alberti with a maximum average utilization of 73.4%, and lastly Dellepiane with a  maximum average utilization of, again, 73.4%.
```{r utilization, echo=FALSE}
ggplot(data = rho,
       aes(x = substr(start_hour, 1, 2), 
           y = 100 * utilization, 
           group = toll_booth_name)) +
  geom_line(aes(color = toll_booth_name)) +
  labs(x = "Hour of day",
       y = "Percentage of utilization",
       title = "Hourly utilization for all toll booth plazas",
       caption = "Figure 12")
```

#### Minimum average number of toll booths required for each plaza
The average utilization presented in Figure 13 uses the amount of servers that can be found in Google Maps. However, those amounts are actually higher than what is theoretically needed to avoid infinite queues. However, these additional toll booths are needed, since the theoretical values are averages, which means there can be situations where the traffic is higher than expected and may require an additional toll booth to cater for it. 
```{r minimumamount, echo=FALSE}
ggplot(data = servers_required, 
       aes(x = substr(start_hour, 1, 2), 
           y = amount, 
           group = toll_booth_name)) +
  geom_line(aes(color = toll_booth_name)) +
  labs(x = "Hour of day", 
       y = "Amount of servers",
       title = "Minimal amount of servers to avoid infinite queues",
       caption = "Figure 13")
```

The table below shows the difference between the actual number of toll booths in each toll booth plaza and the minimum amount required to avoid infinite queues. The greatest difference appears for the Retiro toll booth plaza, where the minimum amount of required toll booths is around 59.4% of the existing toll booths, while for other plazas with high vehicle volumes such ratio is 84.4%.

```{r differencebetweenrealandaverage, echo=FALSE}
servers_required_max <- servers_required %>%
  group_by (
    toll_booth_name
  ) %>%
  summarise (
    amount = max(amount)
  )

servers_required_current <- rho %>%
  group_by (
    toll_booth_name
  ) %>%
  summarise (
    amount = mean(booths)
  )

data.frame (
  name = servers_required_current$toll_booth_name,
  actual = servers_required_current$amount,
  minimum = servers_required_max$amount,
  difference = servers_required_current$amount - servers_required_max$amount
)

rm(servers_required, servers_required_max, servers_required_current,
   servers_required_alberti, characteristics, Lq, Ls, p0_, pd, rho_, Wq, Ws, 
   rho)
```

### Oil prices analysis
The oil prices dataset consists of monthly prices of different types of oil: super, premium, gasoil, and euro. The four of them experienced a steady increase since 2008 until 2019, which is illustrated in Figure 14.

```{r evolution, echo=FALSE}
oil <- unified_ff %>% as_tibble() %>%
  group_by (
    year_,
    oil_type
  ) %>%
  summarise (
    price = mean(price)
  )

ggplot(data = oil, 
       aes(x = year_, y = price, group = oil_type)) +
  geom_line(aes(color = oil_type)) +
  geom_point(aes(color = oil_type)) +
  labs(x = NULL, 
       y = "Price (ARS)",
       title = "Evolution of oil price through years",
       caption = "Figure 14") +
  scale_x_continuous(breaks = 2008:2019)
```

Even though the oil price has been increasing since 2008, inflation in Argentina followed a similar trend, as shown in Figure 15. In order to interpret the actual oil price, the current figures are divided by the yearly mean dollar exchange price (provided by the [Banco Central de la República Argentina](https://www.bcra.gob.ar/PublicacionesEstadisticas/Evolucion_moneda.asp)). 
```{r priceindollars, echo=FALSE}
datasets_dir <- "../datasets/sources"

exchange_rate <- read.csv (
    file = file.path(datasets_dir, "dollar.csv"),
    header = T,
    dec = ".",
    stringsAsFactors = F
  ) %>%
  filter (
    year >= 2008
  ) %>%
  group_by (
    year
  ) %>%
  summarise (
    amount = mean(pesos_per_dollar)
  )

oil_yoy_trend <- oil %>%
  group_by (
    year_
  ) %>%
  summarise (
    price = mean(price)
  )

oil_yoy_trend_dollar <- data.frame (
  year = oil_yoy_trend$year_,
  price = oil_yoy_trend$price / exchange_rate$amount
)

ggplot() +
  geom_line (
    data = exchange_rate, 
    aes(x = year, y = amount, color = "blue")
  ) + 
  geom_point (
    data = exchange_rate, 
    aes(x = year, y = amount, color = "blue")
  ) +
  geom_line (
    data = oil_yoy_trend, 
    aes(x = year_, y = price, color = "red")
  ) +
  geom_point (
    data = oil_yoy_trend, 
    aes(x = year_, y = price, color = "red")
  ) +
  scale_color_discrete(name = "Prices", labels = c("Oil", "ARS per USD")) +
  scale_x_continuous(breaks = 2008:2019) +
  labs(x = NULL, 
       y = "ARS",
       title = "Evolution of oil price and ARS/USD exchange through years",
       caption = "Figure 15")

rm(datasets_dir)
```

Taking differences of the ratio between oil price and ARS/USD exchange rate, Figure 16 shows there are two interesting points in time, where the oil price drops, comparing 2015 with 2016, and afterwars increases, comparing 2016 with 2017.

```{r diffs, echo=FALSE}
oil_increase_diff <- data.frame (
  year = 2009:2019,
  difference = diff(oil_yoy_trend_dollar$price)
)

ggplot(data = oil_increase_diff,
       aes(x = year, y = difference, label = round(difference, 1))) +
  geom_line(linetype = "dashed") +
  geom_point(color = "blue") +
  labs(x = NULL, 
       y = "Price (USD)",
       title = "Difference in oil price through years",
       caption = "Figure 16") +
  scale_x_continuous(breaks = 2009:2019)
```

However, these differences are in the order of cents, as the prices vary at most 20c. The stability of oil price expressed in dollars is illustrated in Figure 17.

```{r dollarprice, echo=FALSE}
ggplot(data = oil_yoy_trend_dollar,
       aes(x = year, y = price, label = round(price, 1))) +
  geom_line(linetype = "dashed") +
  geom_point(color = "blue") +
  labs(x = NULL, 
       y = "Price (USD)",
       title = "Evolution of oil price through years",
       caption = "Figure 17") +
  scale_x_continuous(breaks = 2008:2019)
```